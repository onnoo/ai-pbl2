{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "take2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PPUiesdDQdX",
        "colab_type": "text"
      },
      "source": [
        "# SVM Objective\n",
        "$\\min_{w \\in \\mathbb{R}^p, b \\in \\mathbb{R}} F(w,b)$ where $F(w,b) := \\frac{1}{n} \\sum_{i=1}^{n} \\max\\left \\{ 1 - y_i(< w,x_i >+ b), 0 \\right \\}{}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDxj7oOuDaZF",
        "colab_type": "text"
      },
      "source": [
        "## SGD\n",
        "$\\text{let} \\space \\lambda = \\frac{1}{C}$\n",
        "\n",
        "$\\nabla_{w} \\tilde{F}(w_k, b_k) = \\frac{1}{|B_k|} \\sum_{r \\in B_k}\n",
        "\\begin{cases}\n",
        " -y_rx_r \\qquad \\text{if} \\space y_i < w_k,x_r> +b_k \\leq 1  \\\\ \n",
        " 0 \\space \\qquad\\quad\\space\\space \\text{o.w.}\n",
        "\\end{cases} + \\lambda w_k$  \n",
        "\n",
        "$\\nabla_{b} \\tilde{F}(w_k, b_k) = \\frac{1}{|B_k|} \\sum_{r \\in B_k}\n",
        "\\begin{cases}\n",
        " -y_r \\qquad \\text{if} \\space y_i < w_k,x_r> +b_k \\leq 1  \\\\ \n",
        " 0 \\space \\quad\\quad\\space\\space\\space \\text{o.w.}\n",
        "\\end{cases}$\n",
        "\n",
        "### Update weight\n",
        "$w_{k+1} \\leftarrow w_k - \\eta \\nabla_w \\tilde{F}(w_k,b_k)$  \n",
        "$b_{k+1} \\leftarrow b_k - \\eta \\nabla_b \\tilde{F}(w_k,b_k)$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAte1M_NPgjj",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RUZl6RkQPCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_state = 1126"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEfJpE23PtS2",
        "colab_type": "text"
      },
      "source": [
        "## Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU-pObDzPjNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test =\\\n",
        "    train_test_split(X, y, test_size=0.3, random_state=random_state, stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntC07FgTxdx6",
        "colab_type": "text"
      },
      "source": [
        "## Wine dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq4VpWpSxgqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_wine\n",
        "\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test =\\\n",
        "    train_test_split(X, y, test_size=0.3, random_state=random_state, stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0LK4GTUyDn9",
        "colab_type": "text"
      },
      "source": [
        "## MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP67Cs99yFJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import struct\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "fname_img = \"/content/drive/My Drive/2019/2019-2/인공지능/PBL2/data/newtrain-images-idx3-ubyte\"\n",
        "fname_lbl = \"/content/drive/My Drive/2019/2019-2/인공지능/PBL2/data/newtrain-labels-idx1-ubyte\"\n",
        "\n",
        "with open(fname_lbl, 'rb') as flbl:\n",
        "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
        "        y = np.fromfile(flbl, dtype=np.int8)\n",
        "\n",
        "with open(fname_img, 'rb') as fimg:\n",
        "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
        "        X = np.fromfile(fimg, dtype=np.uint8).reshape(len(y), -1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7VFws2UQWME",
        "colab_type": "text"
      },
      "source": [
        "# SVC class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iMRzzu0DG3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from math import ceil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVWTNoJFDnbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SVC(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, eta=0.1, max_iter=50, C=0.1,\n",
        "                 shuffle=True, randome_state=1, batch_size=32):\n",
        "        self.eta = eta\n",
        "        self.max_iter = max_iter\n",
        "        self.C = C\n",
        "        self.lambda_ = 1.0 / C\n",
        "        self.shuffle = shuffle\n",
        "        self.random_state = random_state\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        self.classes_, y = np.unique(y, return_inverse=True)\n",
        "        num_class, p = len(self.classes_), X.shape[1]\n",
        "        self._initialize_weights(num_class, p)\n",
        "        \n",
        "        r = np.arange(X.shape[0])\n",
        "\n",
        "        for k in range(self.max_iter):\n",
        "            if self.shuffle:\n",
        "                self.rgen.shuffle(r)\n",
        "\n",
        "            for i in range(ceil(X.shape[0] / self.batch_size)):\n",
        "                batch_r = r[self.batch_size * i : self.batch_size * (i + 1)]\n",
        "                sum_w = np.zeros((num_class, p))\n",
        "                sum_b = np.zeros(num_class)\n",
        "\n",
        "                for idx in batch_r:\n",
        "                    xi = X[idx]\n",
        "                    yi = -1 * np.ones(num_class)\n",
        "                    yi[y[idx]] = 1\n",
        "\n",
        "                    conf = yi * (np.dot(self.w_, xi) + self.b_)\n",
        "                    conf_idx = np.where(conf <= 1)\n",
        "\n",
        "                    yt = yi.reshape(yi.shape[0], -1)\n",
        "                    xt = xi.reshape(-1, xi.shape[0])\n",
        "\n",
        "                    sum_w[conf_idx] -= np.dot(yt, xt)[conf_idx]\n",
        "                    sum_b[conf_idx] -= yi[conf_idx]\n",
        "\n",
        "                # Update\n",
        "                self.w_ = self.w_ - self.eta *\\\n",
        "                            (sum_w / len(batch_r) + self.lambda_ * self.w_)\n",
        "                self.b_ = self.b_ - self.eta * sum_b / len(batch_r)\n",
        "    \n",
        "            if k % 10 == 0:\n",
        "                print(f'Iteration {k + 1} / {self.max_iter}')\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _initialize_weights(self, n_class, p):\n",
        "        \"\"\"\n",
        "        Initialize weights to small random numbers.\n",
        "        \"\"\"\n",
        "        self.rgen = np.random.RandomState(self.random_state)\n",
        "        self.w_ = self.rgen.normal(loc=0.0, scale=0.01, size=(n_class, p))\n",
        "        self.b_ = np.zeros(n_class)\n",
        "\n",
        "    def predict(self, X):\n",
        "        dist = np.dot(X, self.w_.T) + self.b_\n",
        "        pred = np.argmax(dist, axis=1)\n",
        "\n",
        "        return self.classes_[pred]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYRHbNoGawaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3aeac472-15a2-432b-962c-6ea867790ebd"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from datetime import datetime\n",
        "\n",
        "# classifier class\n",
        "clf = SVC(max_iter=50, eta=0.001, C=10, randome_state=random_state)\n",
        "\n",
        "start_time = datetime.now()\n",
        "clf.fit(X_train, y_train)\n",
        "end_time = datetime.now()\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "score = accuracy_score(y_test, y_pred)\n",
        "print('learning time:', end_time - start_time)\n",
        "print('accuracy:', score)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 / 50\n",
            "Iteration 11 / 50\n",
            "Iteration 21 / 50\n",
            "Iteration 31 / 50\n",
            "Iteration 41 / 50\n",
            "learning time: 0:01:45.708174\n",
            "accuracy: 0.8659166666666667\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}